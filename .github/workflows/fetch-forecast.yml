name: Fetch Met Éireann Forecasts

on:
  schedule:
    - cron: '10 0 * * *'  # daily at 00:10 UTC
  workflow_dispatch:

jobs:
  fetch_forecast:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install beautifulsoup4 lxml

      - name: Fetch Met Éireann XMLs
        run: |
          mkdir -p forecast_data
          # Portsalon (adjust lat/long if you prefer)
          curl -s "http://openaccess.pf.api.met.ie/metno-wdb2ts/locationforecast?lat=55.200;long=-7.633" -o forecast_data/raw_portsalon.xml
          # Downings (adjust lat/long if you prefer)
          curl -s "http://openaccess.pf.api.met.ie/metno-wdb2ts/locationforecast?lat=55.183;long=-7.833" -o forecast_data/raw_downings.xml

      - name: Convert XML -> JSON (robust merging of precipitation)
        run: |
          python - <<'PY'
          import os, json, hashlib, sys
          from bs4 import BeautifulSoup
          import datetime

          # date window (inclusive start, exclusive end)
          START = datetime.datetime(2025, 8, 28)
          END   = datetime.datetime(2025, 9, 1)

          def assign_precip(entry, pr_tag):
              """Store precipitation as {min,max} if present, else value float."""
              if not pr_tag:
                  return
              minv = pr_tag.get('minvalue')
              maxv = pr_tag.get('maxvalue')
              val  = pr_tag.get('value')
              if minv is not None and maxv is not None:
                  try:
                      entry['Rainfall'] = { "min": float(minv), "max": float(maxv) }
                  except:
                      entry['Rainfall'] = { "min": minv, "max": maxv }
              elif val is not None:
                  try:
                      entry['Rainfall'] = float(val)
                  except:
                      entry['Rainfall'] = val

          def parse_xml_file(path):
              with open(path, 'r', encoding='utf-8') as f:
                  xml = f.read()
              soup = BeautifulSoup(xml, 'lxml-xml')
              forecasts = {}  # key = 'YYYY-MM-DDTHH:00:00Z' -> merged dict

              for time_el in soup.find_all('time'):
                  time_str = time_el.get('from')
                  if not time_str:
                      continue
                  try:
                      dt = datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                  except Exception:
                      # skip unparsable timestamps
                      continue
                  dt_naive = dt.replace(tzinfo=None)
                  if not (START <= dt_naive < END):
                      continue

                  hour_key = dt.strftime('%Y-%m-%dT%H:00:00Z')
                  entry = forecasts.get(hour_key, {'time': hour_key})

                  # location block: temperature, wind, symbol, maybe precipitation
                  loc = time_el.find('location')
                  if loc:
                      temp = loc.find('temperature')
                      if temp and temp.get('value') is not None:
                          try:
                              entry['Temperature'] = float(temp['value'])
                          except:
                              entry['Temperature'] = temp['value']

                      ws = loc.find('windSpeed')
                      if ws and ws.get('mps') is not None:
                          try:
                              entry['WindSpeed'] = round(float(ws['mps']) * 3.6, 1)
                          except:
                              entry['WindSpeed'] = ws['mps']

                      wd = loc.find('windDirection')
                      if wd and wd.get('deg') is not None:
                          try:
                              entry['WindDirection'] = float(wd['deg'])
                          except:
                              entry['WindDirection'] = wd['deg']

                      sym = loc.find('symbol')
                      if sym and sym.get('number') is not None:
                          entry['WeatherSymbol3'] = sym['number']

                      # precipitation sometimes under location
                      pr_loc = loc.find('precipitation')
                      if pr_loc:
                          assign_precip(entry, pr_loc)

                  # precipitation may be a direct child of time
                  pr = time_el.find('precipitation')
                  if pr:
                      assign_precip(entry, pr)

                  # defaults (will be overwritten if real data exists)
                  entry.setdefault('Temperature', None)
                  entry.setdefault('WindSpeed', 0)
                  entry.setdefault('WindDirection', 0)
                  entry.setdefault('Rainfall', None)
                  entry.setdefault('WeatherSymbol3', '1')

                  forecasts[hour_key] = entry

              return forecasts

          # Parse both files
          p_forecasts = parse_xml_file('forecast_data/raw_portsalon.xml') if os.path.exists('forecast_data/raw_portsalon.xml') else {}
          d_forecasts = parse_xml_file('forecast_data/raw_downings.xml') if os.path.exists('forecast_data/raw_downings.xml') else {}

          # helper: sorted list from dict filtered by date prefix
          def slice_by_date_prefix(fdict, prefix):
              return [v for k,v in sorted(fdict.items()) if k.startswith(prefix)]

          # Portsalon = 2025-08-28 ; Downings = 2025-08-29..31
          portsalon_out = slice_by_date_prefix(p_forecasts, '2025-08-28')
          # for downings include entries from the downings parse that are after 2025-08-28
          downings_out = [v for k,v in sorted(d_forecasts.items()) if k > '2025-08-28' ]

          # Ensure directory
          os.makedirs('forecast_data', exist_ok=True)

          def write_if_changed(path, data):
              new_hash = hashlib.md5(json.dumps(data, sort_keys=True).encode()).hexdigest()
              old_hash = None
              try:
                  with open(path,'r', encoding='utf-8') as f:
                      old_hash = hashlib.md5(f.read().encode()).hexdigest()
              except FileNotFoundError:
                  pass
              if new_hash != old_hash:
                  with open(path,'w', encoding='utf-8') as f:
                      json.dump(data, f, indent=2)
                  print("WROTE", path)
              else:
                  print("UNCHANGED", path)

          write_if_changed('forecast_data/portsalon.json', portsalon_out)
          write_if_changed('forecast_data/downings.json', downings_out)

          print("Done.")
          PY

      - name: Commit and push JSON
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git add forecast_data/portsalon.json forecast_data/downings.json
          git commit -m "Update forecasts [skip ci]" || echo "No changes"
          git push
